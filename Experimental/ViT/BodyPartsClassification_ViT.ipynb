{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6779,"status":"ok","timestamp":1711336290925,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"cweaSxk5HRHd","outputId":"74d7328e-5087-404c-ee17-7e7d85cf7809"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-31 15:21:41.060207: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'tensorflow_addons'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator, load_img, img_to_array\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorBoard\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvit_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vit\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/vit_keras/vit.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtx\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, utils\n\u001b[1;32m      8\u001b[0m ConfigDict \u001b[38;5;241m=\u001b[39m tx\u001b[38;5;241m.\u001b[39mTypedDict(\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfigDict\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     },\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m CONFIG_B: ConfigDict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m3072\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m768\u001b[39m,\n\u001b[1;32m     25\u001b[0m }\n","File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/vit_keras/layers.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pylint: disable=arguments-differ,missing-function-docstring,missing-class-docstring,unexpected-keyword-arg,no-value-for-parameter\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_addons\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfa\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mregister_keras_serializable()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClassToken\u001b[39;00m(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLayer):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Append a class token to an input layer.\"\"\"\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_addons'"]}],"source":["import tensorflow as tf\n","import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.callbacks import TensorBoard\n","from vit_keras import vit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27313,"status":"ok","timestamp":1711336318232,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"yC-TUF78HXBT","outputId":"0aa25ad8-e3b6-47e0-e6b5-35aee4c70ee9"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1711336318233,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"M_h2WiRbHRHi"},"outputs":[],"source":["# Khai báo các thông số\n","img_width, img_height = 224, 224\n","batch_size = 16\n","epochs = 20\n","num_classes = 3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":751,"status":"ok","timestamp":1711336318979,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"tuPitnOdHRHk","outputId":"8cc65ee3-840f-4f89-f923-78dc8574f381"},"outputs":[],"source":["# Đường dẫn đến thư mục chứa dữ liệu\n","data_dir = '../dataset/0.5'\n","\n","# Danh sách các lớp (classes) là các thư mục con trong thư mục chứa dữ liệu\n","classes = os.listdir(data_dir)\n","print(classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":989,"status":"ok","timestamp":1711336319965,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"qewlWAP_HRHl"},"outputs":[],"source":["# Tạo empty lists để lưu trữ đường dẫn hình ảnh và nhãn tương ứng\n","image_paths = []\n","labels = []\n","\n","# Lặp qua mỗi lớp\n","for class_label in classes:\n","  class_dir = os.path.join(data_dir, class_label)\n","  # Lặp qua mỗi hình ảnh trong mỗi lớp\n","  for image_name in os.listdir(class_dir):\n","    image_path = os.path.join(class_dir, image_name)\n","    image_paths.append(image_path)\n","    labels.append(class_label)\n","\n","# Chia dữ liệu thành tập huấn luyện và tập validation\n","train_image_paths, val_image_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n","\n","# Tạo DataFrame cho tập huấn luyện\n","train_dataframe = pd.DataFrame({'image_path': train_image_paths, 'label': train_labels})\n","# Tạo DataFrame cho tập validation\n","val_dataframe = pd.DataFrame({'image_path': val_image_paths, 'label': val_labels})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1711336319965,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"A_6ulj1OHRHl","outputId":"702b8624-c53c-4352-fccd-0c432c278004"},"outputs":[],"source":["# Tạo ImageDataGenerator cho tập huấn luyện\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,  # Chuẩn hóa lại giá trị pixel về khoảng [0,1]\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","# Tạo ImageDataGenerator cho tập validation, chỉ cần rescale lại giá trị pixel\n","val_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Tạo generator cho tập huấn luyện\n","train_generator = train_datagen.flow_from_dataframe(\n","    dataframe=train_dataframe,  # DataFrame chứa đường dẫn hình ảnh và nhãn cho tập huấn luyện\n","    x_col=\"image_path\",\n","    y_col=\"label\",\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")\n","\n","# Tạo generator cho tập validation\n","validation_generator = val_datagen.flow_from_dataframe(\n","    dataframe=val_dataframe,  # DataFrame chứa đường dẫn hình ảnh và nhãn cho tập validation\n","    x_col=\"image_path\",\n","    y_col=\"label\",\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='categorical'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5043,"status":"ok","timestamp":1711336325005,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"nFIwzVUPM3d7","outputId":"a83f30cc-0585-4ea1-e4a0-fc192a0b813d"},"outputs":[],"source":["validation_generator[1][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9441,"status":"ok","timestamp":1711336334442,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"wmNGCojrHRHm","outputId":"a2d209ee-791a-4be1-bdf1-24501e1908e9"},"outputs":[],"source":["# Tạo mô hình Vision Transformer\n","model = vit.vit_b16(\n","    image_size=img_width,\n","    activation='softmax',\n","    pretrained=True,\n","    include_top=True,\n","    pretrained_top=False,\n","    classes=num_classes,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":538,"status":"ok","timestamp":1711336334968,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"Jcfd6YSrHRHm","outputId":"025d832d-678a-44c1-9b66-8d911a4537ee"},"outputs":[],"source":["# Compile model\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1711336334968,"user":{"displayName":"Thiện Nguyễn Phước","userId":"17408990047579158111"},"user_tz":-420},"id":"58dSliUBHRHn"},"outputs":[],"source":["# Định nghĩa callback để ghi log TensorBoard\n","log_dir = \"/content/drive/MyDrive/Colab Notebooks/Experimental/ViT/logs/fit\"\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"piLsUR-0HRHn","outputId":"ae251627-c7c7-4cc2-9e1c-770221841c55"},"outputs":[],"source":["# Train the model\n","history = model.fit(train_generator,\n","                    steps_per_epoch=train_generator.samples // batch_size,\n","                    epochs=epochs,\n","                    validation_data=validation_generator,\n","                    validation_steps=validation_generator.samples // batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QqvZkHNxJJzg"},"outputs":[],"source":["# Evaluate the model\n","test_loss, test_acc = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n","print('Test accuracy:', test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8Qlr9LUiUVE"},"outputs":[],"source":["image_path = '/content/drive/MyDrive/Colab Notebooks/Experimental/test_image.jpg'\n","img = load_img(image_path, target_size=(img_width, img_height))\n","img_array = img_to_array(img)\n","\n","# Rescale hình ảnh\n","img_array /= 255.\n","img_array = img_array.reshape(1, 224, 224, 3)\n","img_array.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XkC7DJM9jM0p"},"outputs":[],"source":["model.predict(img_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMdoK0kHHRHo"},"outputs":[],"source":["# Visualize loss and accuracy\n","import matplotlib.pyplot as plt\n","\n","train_loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","train_acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","epochs_range = range(1, epochs+1)\n","\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, train_loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, train_acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
